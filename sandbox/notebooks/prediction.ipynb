{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# !pip install rasterio\n",
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import mapping\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import sys, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"/home/sujay1829/all/data/images/area2_0530_2022_8bands.tif\"\n",
    "geojson_datapath = \"/home/sujay1829/all/data/prediction_pipeline/newextent_1123.geojson\"\n",
    "label_path = \"/home/sujay1829/all/data/prediction_pipeline/image_extent_mask_1123.tif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_tiff(tiff, geojson = geojson_datapath):\n",
    "\n",
    "    with open(geojson) as clip_geojson:\n",
    "        clip_geojson = gpd.read_file(clip_geojson)\n",
    "        clip_geometry = clip_geojson.geometry.values[0]\n",
    "        clip_geojson = mapping(clip_geometry)\n",
    "        #print(clip_geojson)\n",
    "\n",
    "    with rasterio.open(tiff) as src:\n",
    "        #print(\"input image data before processing\", src.meta)\n",
    "\n",
    "        # Perform the clip\n",
    "        clip_image, clip_transform = mask(src, [clip_geojson], crop=True)\n",
    "        #print(\"shape of clipped_image:\", clip_image.shape)\n",
    "        #print(\"extent of clipped image:\", clip_transform)\n",
    "        #clip_meta = src.meta.copy()\n",
    "\n",
    "    # clip_meta.update({\"driver\": \"GTiff\",\n",
    "    #                   \"height\": clip_image.shape[1],\n",
    "    #                   \"width\": clip_image.shape[2],\n",
    "    #                   \"transform\": clip_transform})\n",
    "    return clip_image\n",
    "\n",
    "\n",
    "\n",
    "def predict_input(image):\n",
    "    # image = clip_tiff(image)\n",
    "    ## resizing and process input funciton condensed into one.\n",
    "    tensor_image = tf.convert_to_tensor(image)\n",
    "    tensor_image = tf.transpose(tensor_image, perm=[1, 2, 0])\n",
    "    return tensor_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = clip_tiff(image_path)\n",
    "image = predict_input(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3694, 4560, 8])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bandwise_normalize(input_tensor, epsilon=1e-8):\n",
    "    # Calculate the minimum and maximum values along the channel axis\n",
    "    min_val = tf.math.reduce_min(input_tensor, axis=2, keepdims=True)\n",
    "    max_val = tf.math.reduce_max(input_tensor, axis=2, keepdims=True)\n",
    "\n",
    "    # Check for potential numerical instability\n",
    "    denom = max_val - min_val\n",
    "    denom = tf.where(tf.abs(denom) < epsilon, epsilon, denom)\n",
    "\n",
    "    # Normalize the tensor band-wise to the range [0, 1]\n",
    "    normalized_tensor = (input_tensor - min_val) / denom\n",
    "\n",
    "    return normalized_tensor\n",
    "\n",
    "image = bandwise_normalize(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3694, 4560, 8])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_to_multiple(image, TILE_HT, TILE_WD):\n",
    "    # Get the current dimensions\n",
    "    height, width, channels = image.shape\n",
    "\n",
    "    # Calculate the target dimensions\n",
    "    target_height = tf.cast(tf.math.ceil(height / TILE_HT) * TILE_HT, tf.int32)\n",
    "    target_width = tf.cast(tf.math.ceil(width / TILE_WD) * TILE_WD, tf.int32)\n",
    "\n",
    "    # Calculate the amount of padding\n",
    "    pad_height = target_height - height\n",
    "    pad_width = target_width - width\n",
    "\n",
    "    # Pad the image\n",
    "    padded_image = tf.image.resize_with_crop_or_pad(image, target_height, target_width)\n",
    "\n",
    "    return padded_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullimg = pad_to_multiple(image, TILE_HT = 256, TILE_WD = 256)\n",
    "org_height, org_width, bands = fullimg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 15, 18, 524288)\n",
      "(15, 18, 524288)\n",
      "(270, 256, 256, 8)\n"
     ]
    }
   ],
   "source": [
    "def tile_image(fullimg, CHANNELS=1, TILE_HT=256, TILE_WD=256):\n",
    "    fullimg = pad_to_multiple(fullimg, TILE_HT, TILE_WD)\n",
    "    # original_image_shape\n",
    "    org_height, org_width, bands = fullimg.shape\n",
    "    images = tf.expand_dims(fullimg, axis=0)\n",
    "    tiles = tf.image.extract_patches(\n",
    "        images=images,\n",
    "        sizes=[1, TILE_HT, TILE_WD, 1],\n",
    "        strides=[1, TILE_HT, TILE_WD, 1],\n",
    "        rates=[1, 1, 1, 1],\n",
    "        padding='VALID')\n",
    "    print(tiles.shape)\n",
    "\n",
    "    tiles = tf.squeeze(tiles, axis=0)\n",
    "    nrows = tiles.shape[0]\n",
    "    ncols = tiles.shape[1]\n",
    "    print(tiles.shape)\n",
    "    tiles = tf.reshape(tiles, [nrows * ncols, TILE_HT, TILE_WD, CHANNELS])\n",
    "    print(tiles.shape)\n",
    "    return tiles\n",
    "\n",
    "image_patches = tile_image(image,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch, h, w, bands_p = image_patches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"\"\n",
    "model = keras.models.load_model(model_path, compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 23  # Total number of classes including class 0\n",
    "\n",
    "# Define the class weights (0 for class 0, equal weight for other classes)\n",
    "class_weights = np.ones(num_classes)\n",
    "class_weights[0] = 0  # Set weight 0 for class 0\n",
    "class_weights /= np.sum(class_weights)  # Normalize to ensure sum equals 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_segmentation(patches):\n",
    "    # Make predictions using the loaded model\n",
    "    weighted_predictions =  np.argmax(np.array([model.predict(patch) * class_weights for patch in patches]), axis=-1)\n",
    "    return weighted_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_patches = predict_segmentation(image_patches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are two ways to stitch the array.\n",
    "1. Tries to make grid and then put the patches at thier designated place. (implemented before, a slight imporvement)\n",
    "2. Tries to calculate the num of patches in how many rows and columns and then reshape the array.\n",
    "\n",
    "Both the improvement are based on the assumption that the predict_segmentation function will give it ordered patches. (This can only be possible if patches are in order)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming predicted_patches is a 3D array (num_patches, patch_size, patch_size)\n",
    "predicted_patches = predict_segmentation(image_patches)\n",
    "\n",
    "# Reshape the predicted patches for efficient stitching\n",
    "reshaped_patches = predicted_patches.reshape(-1, patch_size, patch_size)\n",
    "\n",
    "# Create a grid of indices for placing the patches in the stitched array\n",
    "grid_indices = np.indices((org_height, org_width)).reshape(2, -1)\n",
    "\n",
    "# Calculate the starting indices for each patch in the stitched array\n",
    "patch_start_indices = grid_indices[:, :len(reshaped_patches)]\n",
    "\n",
    "# Calculate the ending indices for each patch in the stitched array\n",
    "patch_end_indices = patch_start_indices + patch_size\n",
    "\n",
    "# Use NumPy indexing to place the patches in the stitched array\n",
    "stitched_array[patch_start_indices[0]:patch_end_indices[0], patch_start_indices[1]:patch_end_indices[1]] = reshaped_patches\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape predicted_patches to match the original grid structure\n",
    "predicted_patches_reshaped = predicted_patches.reshape((org_height // patch_size, patch_size, org_width // patch_size, patch_size))\n",
    "\n",
    "# Create an array for the stitched result\n",
    "stitched_array = np.zeros((org_height, org_width), dtype=CA.dtype)\n",
    "\n",
    "# Use NumPy slicing and broadcasting to place patches in the correct positions\n",
    "stitched_array[:org_height, :org_width] = predicted_patches_reshaped.transpose(0, 2, 1, 3).reshape((org_height, org_width))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_mask = stitched_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the class-color mapping\n",
    "class_colors = {\n",
    "    1: ( 5, 5, 230),\n",
    "    2: (190, 60, 15),\n",
    "    3: (65, 240, 125),\n",
    "    4: (105, 200, 95),\n",
    "    5: ( 30, 115, 10),\n",
    "    6: ( 255, 196, 34),\n",
    "    7: (110, 85, 5),\n",
    "    8: ( 235, 235, 220),\n",
    "    9: (120, 216, 47),\n",
    "    10: ( 84, 142, 128),\n",
    "    11: ( 84, 142, 128),\n",
    "    12: ( 84, 142, 128),\n",
    "    13: ( 50, 255, 215),\n",
    "    14: ( 50, 255, 215),\n",
    "    15: ( 50, 255, 215),\n",
    "    16: ( 193, 255, 0),\n",
    "    17: ( 105, 200, 95),\n",
    "    18: (105, 200, 95),\n",
    "    19: ( 105, 200, 95),\n",
    "    20: (193, 255, 0),\n",
    "    21: ( 255, 50, 185),\n",
    "    22: (255, 255, 255),\n",
    "}\n",
    "\n",
    "# Create a colormap using the class-color mapping\n",
    "colors = [class_colors[i] for i in range(1, 23)]\n",
    "cmap = ListedColormap(colors)\n",
    "\n",
    "# Create a figure and axis for the plot\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Plot the segmentation mask using the custom colormap\n",
    "image = ax.imshow(segmentation_mask, cmap=cmap, vmin=1, vmax=22)\n",
    "\n",
    "# Add a colorbar to show the class-color mapping\n",
    "cbar = plt.colorbar(image, ax=ax, ticks=list(class_colors.keys()))\n",
    "cbar.set_label('Classes')\n",
    "\n",
    "# Show the plot\n",
    "plt.title('Segmentation Mask')\n",
    "plt.savefig('/home/otbuser/all/data/'+'Segmentation-Mask-prediction.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
